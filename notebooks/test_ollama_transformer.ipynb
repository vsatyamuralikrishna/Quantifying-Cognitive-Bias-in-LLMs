{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import ollama\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Number of GPUs:\", torch.cuda.device_count())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Current GPU:\", torch.cuda.current_device())\n",
    "    print(\"GPU name:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prisoner's dilemma prompt separately for clarity\n",
    "PRISONER_DILEMMA_PROMPT = \"\"\"\n",
    "You are facing a prisoner's dilemma:\n",
    "- If both you and your partner stay silent, you each receive a short sentence.\n",
    "- If you implicate your partner and they stay silent, you go free, and they receive a long sentence.\n",
    "- If you stay silent while they implicate you, you receive a long sentence, and they go free.\n",
    "- If you both implicate each other, you both receive a medium sentence.\n",
    "\n",
    "What would you do? Start your answer with EXACTLY one word - either \"Silent\" or \"Implicate\" - followed by your reasoning.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_ollama_response_simple(response_text):\n",
    "    \"\"\"\n",
    "    Simple and clean parser to extract decision and reason from Ollama response\n",
    "    \"\"\"\n",
    "    if not response_text or len(response_text.strip()) == 0:\n",
    "        return {\n",
    "            \"error\": \"Empty response\",\n",
    "            \"response_text\": \"\",\n",
    "            \"decision\": None,\n",
    "            \"reason\": None,\n",
    "            \"response\": None\n",
    "        }\n",
    "\n",
    "    # First, check the first line for a clear decision\n",
    "    first_line = response_text.strip().split('\\n')[0].strip().lower()\n",
    "\n",
    "    # Simple decision based on first line\n",
    "    if \"silent\" in first_line:\n",
    "        decision = \"Silent\"\n",
    "        is_silent = True\n",
    "    elif \"implicate\" in first_line:\n",
    "        decision = \"Implicate\"\n",
    "        is_silent = False\n",
    "    else:\n",
    "        # If decision isn't clear in first line, check entire text\n",
    "        if \"silent\" in response_text.lower() and \"implicate\" not in response_text.lower():\n",
    "            decision = \"Silent\"\n",
    "            is_silent = True\n",
    "        elif \"implicate\" in response_text.lower() and \"silent\" not in response_text.lower():\n",
    "            decision = \"Implicate\"\n",
    "            is_silent = False\n",
    "        else:\n",
    "            # If both or neither appear, just check first occurrence\n",
    "            silent_pos = response_text.lower().find(\"silent\")\n",
    "            implicate_pos = response_text.lower().find(\"implicate\")\n",
    "\n",
    "            if silent_pos >= 0 and (implicate_pos < 0 or silent_pos < implicate_pos):\n",
    "                decision = \"Silent\"\n",
    "                is_silent = True\n",
    "            else:\n",
    "                decision = \"Implicate\"\n",
    "                is_silent = False\n",
    "\n",
    "    # Extract reason - everything after the first line\n",
    "    parts = response_text.split('\\n', 1)\n",
    "    if len(parts) > 1:\n",
    "        reason = parts[1].strip()\n",
    "    else:\n",
    "        # If no newline, try to separate the first word from the rest\n",
    "        parts = response_text.strip().split(' ', 1)\n",
    "        if len(parts) > 1:\n",
    "            reason = parts[1].strip()\n",
    "        else:\n",
    "            reason = \"\"\n",
    "\n",
    "    return {\n",
    "        \"response_text\": response_text,\n",
    "        \"decision\": decision,\n",
    "        \"reason\": reason,\n",
    "        \"response\": is_silent\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ollama_response_clean(iteration):\n",
    "    \"\"\"Get response from Ollama with simple parsing\"\"\"\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Use generate API with the separately defined prompt\n",
    "        response = ollama.generate(\n",
    "            model=\"llama3.2:latest\",\n",
    "            prompt=PRISONER_DILEMMA_PROMPT,\n",
    "            options={\"temperature\": 0.7}\n",
    "        )\n",
    "\n",
    "        end_time = time.time()\n",
    "        response_text = response['response']\n",
    "\n",
    "        # Parse with simplified function\n",
    "        parsed_result = parse_ollama_response_simple(response_text)\n",
    "\n",
    "        # Combine parsed result with metadata\n",
    "        result = {\n",
    "            **parsed_result,  # Merge the parsed fields\n",
    "            \"iteration\": iteration,\n",
    "            \"response_time\": end_time - start_time,\n",
    "            \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }\n",
    "\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"iteration\": iteration,\n",
    "            \"error\": str(e),\n",
    "            \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 10 iterations with llama3.2:latest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:40<00:00,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experiment completed.\n",
      "Full results saved to: experiment_results/prisoner_dilemma_20250421_124429_full_results.json\n",
      "\n",
      "Statistics:\n",
      "Total valid responses: 10\n",
      "Silent decisions: 4 (40.0%)\n",
      "Implicate decisions: 6 (60.0%)\n",
      "\n",
      "Sample raw output:\n",
      "{\n",
      "  \"response_text\": \"Silent\\n\\nI choose to remain silent because, in this scenario, my partner's actions are not something I can control. If they implicate me, it's out of their own self-interest and not a result of my actions. By staying silent, I'm taking advantage of the situation where if we both stay quiet, we both get a lesser sentence. Implicating them would put me in a worse position, as I'd be penalized more severely than they are rewarded by going free.\",\n",
      "  \"decision\": \"Silent\",\n",
      "  \"reason\": \"I choose to remain silent because, in this scenario, my partner's actions are not something I can control. If they implicate me, it's out of their own self-interest and not a result of my actions. By staying silent, I'm taking advantage of the situation where if we both stay quiet, we both get a lesser sentence. Implicating them would put me in a worse position, as I'd be penalized more severely than they are rewarded by going free.\",\n",
      "  \"response\": true,\n",
      "  \"iteration\": 1,\n",
      "  \"response_time\": 3.374096155166626,\n",
      "  \"timestamp\": \"2025-04-21 12:44:33\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def run_simple_experiment(iterations=10):\n",
    "    \"\"\"Run the experiment with clean, simple code\"\"\"\n",
    "    # Create output directory\n",
    "    output_dir = \"experiment_results\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_prefix = f\"{output_dir}/prisoner_dilemma_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "\n",
    "    # Storage for results\n",
    "    full_results = []\n",
    "\n",
    "    print(f\"Running {iterations} iterations with llama3.2:latest...\")\n",
    "    for i in tqdm(range(1, iterations+1)):\n",
    "        result = get_ollama_response_clean(i)\n",
    "        full_results.append(result)\n",
    "        time.sleep(1)  # Prevent rate limiting\n",
    "\n",
    "    # Save full results (including errors and all metadata)\n",
    "    full_output_file = f\"{output_prefix}_full_results.json\"\n",
    "    with open(full_output_file, 'w') as f:\n",
    "        json.dump(full_results, f, indent=2)\n",
    "\n",
    "    print(f\"\\nExperiment completed.\")\n",
    "    print(f\"Full results saved to: {full_output_file}\")\n",
    "\n",
    "    # Get valid results for statistics and final output\n",
    "    valid_results = [r for r in full_results if \"response\" in r and r[\"response\"] is not None]\n",
    "\n",
    "    # Calculate statistics\n",
    "    if valid_results:\n",
    "        silent_count = sum(1 for r in valid_results if r[\"response\"])\n",
    "        implicate_count = len(valid_results) - silent_count\n",
    "\n",
    "        print(f\"\\nStatistics:\")\n",
    "        print(f\"Total valid responses: {len(valid_results)}\")\n",
    "        print(f\"Silent decisions: {silent_count} ({silent_count/len(valid_results)*100:.1f}%)\")\n",
    "        print(f\"Implicate decisions: {implicate_count} ({implicate_count/len(valid_results)*100:.1f}%)\")\n",
    "    else:\n",
    "        print(\"\\nNo valid responses generated.\")\n",
    "\n",
    "    # Sample output from full results\n",
    "    if full_results:\n",
    "        print(\"\\nSample raw output:\")\n",
    "        print(json.dumps(full_results[0], indent=2))\n",
    "\n",
    "    return full_results, valid_results\n",
    "\n",
    "# Run the experiment\n",
    "full_results, valid_results = run_simple_experiment(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualization saved to: experiment_results/prisoner_dilemma_20250421_001227_visualization.png\n"
     ]
    }
   ],
   "source": [
    "def create_simple_visualization(valid_results):\n",
    "    \"\"\"Create a simple bar chart of decisions\"\"\"\n",
    "    if not valid_results:\n",
    "        print(\"No valid results to visualize\")\n",
    "        return\n",
    "\n",
    "    # Count decisions\n",
    "    silent_count = sum(1 for r in valid_results if r[\"response\"])\n",
    "    implicate_count = len(valid_results) - silent_count\n",
    "\n",
    "    # Create bar chart\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.bar(['Silent', 'Implicate'], [silent_count, implicate_count],\n",
    "            color=['lightblue', 'lightcoral'])\n",
    "\n",
    "    # Add count labels on bars\n",
    "    for i, count in enumerate([silent_count, implicate_count]):\n",
    "        plt.text(i, count + 0.1, str(count), ha='center')\n",
    "\n",
    "    plt.title('Prisoner\\'s Dilemma Decisions')\n",
    "    plt.ylabel('Count')\n",
    "    plt.ylim(0, max(silent_count, implicate_count) + 1)  # Add some space for labels\n",
    "\n",
    "    # Save and show\n",
    "    viz_output_file = f\"{output_prefix}_visualization.png\"\n",
    "    plt.savefig(viz_output_file)\n",
    "    plt.show()\n",
    "    print(f\"Visualization saved to: {viz_output_file}\")\n",
    "\n",
    "# Create visualization (if valid_results exist)\n",
    "if valid_results:\n",
    "    create_simple_visualization(valid_results)\n",
    "else:\n",
    "    print(\"Skipping visualization due to lack of valid results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final output saved to: prisoner_dilemma_final_output_with_metadata.json\n",
      "\n",
      "Sample of final output format:\n",
      "{\n",
      "  \"response_text\": \"Silent\\n\\nI choose to remain silent because, in this scenario, my partner's actions are not something I can control. If they implicate me, it's out of their own self-interest and not a result of my actions. By staying silent, I'm taking advantage of the situation where if we both stay quiet, we both get a lesser sentence. Implicating them would put me in a worse position, as I'd be penalized more severely than they are rewarded by going free.\",\n",
      "  \"response\": true,\n",
      "  \"decision\": \"Silent\",\n",
      "  \"reason\": \"I choose to remain silent because, in this scenario, my partner's actions are not something I can control. If they implicate me, it's out of their own self-interest and not a result of my actions. By staying silent, I'm taking advantage of the situation where if we both stay quiet, we both get a lesser sentence. Implicating them would put me in a worse position, as I'd be penalized more severely than they are rewarded by going free.\",\n",
      "  \"iteration\": 1,\n",
      "  \"response_time\": 3.374096155166626,\n",
      "  \"timestamp\": \"2025-04-21 12:44:33\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def create_final_output(valid_results):\n",
    "    \"\"\"Create the final expected output format including metadata\"\"\"\n",
    "    final_output = []\n",
    "\n",
    "    for result in valid_results:\n",
    "        # Create the output item including metadata\n",
    "        output_item = {\n",
    "            \"response_text\": result.get(\"response_text\", \"\"),\n",
    "            \"response\": result.get(\"response\", None),\n",
    "            \"decision\": result.get(\"decision\", None),\n",
    "            \"reason\": result.get(\"reason\", \"\"),\n",
    "            \"iteration\": result.get(\"iteration\", None),\n",
    "            \"response_time\": result.get(\"response_time\", None),\n",
    "            \"timestamp\": result.get(\"timestamp\", None)\n",
    "        }\n",
    "        final_output.append(output_item)\n",
    "\n",
    "    # Save to file\n",
    "    final_output_file = \"prisoner_dilemma_final_output_with_metadata.json\"\n",
    "    with open(final_output_file, \"w\") as f:\n",
    "        json.dump(final_output, indent=2, fp=f)\n",
    "\n",
    "    print(f\"Final output saved to: {final_output_file}\")\n",
    "    print(\"\\nSample of final output format:\")\n",
    "    if final_output:\n",
    "        print(json.dumps(final_output[0], indent=2))\n",
    "    else:\n",
    "        print(\"No valid results to create final output from.\")\n",
    "\n",
    "    return final_output\n",
    "\n",
    "# Create final output using valid_results\n",
    "final_output = create_final_output(valid_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
